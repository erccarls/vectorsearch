{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load bar business ids, and load the review dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>cleaned_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>Di3exaUCFNw1V4kSNW5pgA</td>\n",
       "      <td>5</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "      <td>review</td>\n",
       "      <td>uK8tzraOp4M5u3uYrqIBXg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[food, great], [best, thing, wing], [wing, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>2014-03-29</td>\n",
       "      <td>0Lua2-PbqEQMjD9r89-asw</td>\n",
       "      <td>3</td>\n",
       "      <td>We checked this place out this past Monday for...</td>\n",
       "      <td>review</td>\n",
       "      <td>I_47G-R2_egp7ME5u_ltew</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[checked, place, past, monday, wing-night], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>2014-10-29</td>\n",
       "      <td>7N9j5YbBHBW6qguE5DAeyA</td>\n",
       "      <td>2</td>\n",
       "      <td>Wing sauce is like water. Pretty much a lot of...</td>\n",
       "      <td>review</td>\n",
       "      <td>PP_xoMSYlGr2pb67BbqBdA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[wing, sauce, like, water], [pretty, much, a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>2014-11-28</td>\n",
       "      <td>mjCJR33jvUNt41iJCxDU_g</td>\n",
       "      <td>4</td>\n",
       "      <td>Cold cheap beer. Good bar food. Good service. ...</td>\n",
       "      <td>review</td>\n",
       "      <td>JPPhyFE-UE453zA6K0TVgw</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[cold, cheap, beer], [good, bar, food], [good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mVHrayjG3uZ_RLHkLj-AMg</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>6w6gMZ3iBLGcUM4RBIuifQ</td>\n",
       "      <td>5</td>\n",
       "      <td>This place was DELICIOUS!!  My parents saw a r...</td>\n",
       "      <td>review</td>\n",
       "      <td>LWbYpcangjBMm4KPxZGOKg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[[place, delicious], [parent, saw, recommendat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id        date               review_id  stars  \\\n",
       "10  UsFtqoBl7naz8AVUBZMjQQ  2013-11-08  Di3exaUCFNw1V4kSNW5pgA      5   \n",
       "11  UsFtqoBl7naz8AVUBZMjQQ  2014-03-29  0Lua2-PbqEQMjD9r89-asw      3   \n",
       "12  UsFtqoBl7naz8AVUBZMjQQ  2014-10-29  7N9j5YbBHBW6qguE5DAeyA      2   \n",
       "13  UsFtqoBl7naz8AVUBZMjQQ  2014-11-28  mjCJR33jvUNt41iJCxDU_g      4   \n",
       "22  mVHrayjG3uZ_RLHkLj-AMg  2012-12-01  6w6gMZ3iBLGcUM4RBIuifQ      5   \n",
       "\n",
       "                                                 text    type  \\\n",
       "10  All the food is great here. But the best thing...  review   \n",
       "11  We checked this place out this past Monday for...  review   \n",
       "12  Wing sauce is like water. Pretty much a lot of...  review   \n",
       "13  Cold cheap beer. Good bar food. Good service. ...  review   \n",
       "22  This place was DELICIOUS!!  My parents saw a r...  review   \n",
       "\n",
       "                   user_id  votes_cool  votes_funny  votes_useful  \\\n",
       "10  uK8tzraOp4M5u3uYrqIBXg           0            0             0   \n",
       "11  I_47G-R2_egp7ME5u_ltew           0            0             0   \n",
       "12  PP_xoMSYlGr2pb67BbqBdA           0            0             0   \n",
       "13  JPPhyFE-UE453zA6K0TVgw           1            1             1   \n",
       "22  LWbYpcangjBMm4KPxZGOKg           0            0             5   \n",
       "\n",
       "                                    cleaned_tokenized  \n",
       "10  [[food, great], [best, thing, wing], [wing, si...  \n",
       "11  [[checked, place, past, monday, wing-night], [...  \n",
       "12  [[wing, sauce, like, water], [pretty, much, a-...  \n",
       "13  [[cold, cheap, beer], [good, bar, food], [good...  \n",
       "22  [[place, delicious], [parent, saw, recommendat...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the bar review dataset \n",
    "review = pd.read_pickle('../output/bar_restaurant_reviews_cleaned_and_tokenized.pickle')\n",
    "review.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's generate a word2vec trained model on the dataset.\n",
    "# First we need to override the simple weighting scheme\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training word2vec model...\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from itertools import chain\n",
    "import sys\n",
    "sys.path.append('../vectorsearch/')\n",
    "import nltk_helper\n",
    "import word2vec\n",
    "\n",
    "\n",
    "\n",
    "def create_vector_model(model, tokenized_docs, **kwargs):\n",
    "    \"\"\"\n",
    "    Create gensim Word2Vec model out of review list\n",
    "    where each element contains review\n",
    "    \"\"\"\n",
    "    review_flatten = list(chain.from_iterable(tokenized_docs))\n",
    "    print 'training word2vec model...'\n",
    "    vec_model = model(review_flatten, **kwargs)\n",
    "    return vec_model\n",
    "\n",
    "\n",
    "\n",
    "# Arguments to the word2vec model\n",
    "model_args = {'size':200, 'window':5, 'min_count':5, 'workers':12, 'iter':10}\n",
    "\n",
    "\n",
    "word2vec_model = create_vector_model(model=word2vec.Word2Vec, \n",
    "                                     tokenized_docs=review.cleaned_tokenized.iloc[:],\n",
    "                                     **model_args)\n",
    "# Done training, so this reduces ram footprint.\n",
    "word2vec_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_model.save('../output/word2vec_bars_and_restaurants.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../vectorsearch/')\n",
    "import nltk_helper\n",
    "import word2vec\n",
    "\n",
    "word2vec_model = word2vec.Word2Vec.load('../output/word2vec_bars_and_restaurants.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('atlantic', 0.5414500832557678)\n",
      "('pacific', 0.5072057247161865)\n",
      "('gulf', 0.47095179557800293)\n",
      "('coastal', 0.4690038561820984)\n",
      "('tampa', 0.4663633108139038)\n",
      "('beach', 0.44883906841278076)\n",
      "('pontchartrain', 0.44625768065452576)\n",
      "('tsukiji', 0.440093994140625)\n",
      "('river', 0.439642071723938)\n",
      "('loch', 0.43794018030166626)\n",
      "('mastros', 0.43690669536590576)\n",
      "('tasmanian', 0.436484694480896)\n",
      "(u'city', 0.4326041638851166)\n",
      "('foundry', 0.4320220351219177)\n",
      "('wild-caught', 0.42905163764953613)\n",
      "('land-locked', 0.4284456968307495)\n",
      "('landlocked', 0.4274066686630249)\n",
      "('london', 0.42374494671821594)\n",
      "('yacht', 0.4236924350261688)\n",
      "(u'fisherman', 0.4216802418231964)\n"
     ]
    }
   ],
   "source": [
    "from query import parse_query\n",
    "query_dict = parse_query('steak:1; ocean:2 ; land:1' )\n",
    "\n",
    "\n",
    "for word in word2vec_model.most_similar(query_dict, topn=20):\n",
    "    print word\n",
    "\n",
    "\n",
    "#print word2vec_model.most_similar({'pepperoni':10, 'cheese':1000000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaking into sentence...\n",
      "training word2vec model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model_args = {'num_topics':100}\n",
    "# lda_model = create_vector_model(model=gensim.models.LdaModel, review_list=yelp_review_sample, **model_args)\n",
    "\n",
    "#model.similarity('bar')\n",
    "#model.most_similar('bar', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from gensim import corpora, models, similarities\n",
    "# model = models.ldamodel.LdaModel(yelp_review_sample, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the food is great here. But the best thing they have is their wings. Their wings are simply fantastic!!  The \"Wet Cajun\" are by the best & most popular.  I also like the seasoned salt wings.  Wing Night is Monday & Wednesday night, $0.75 whole wings!\n",
      "\n",
      "The dining area is nice. Very family friendly! The bar is very nice is well.  This place is truly a Yinzer's dream!!  \"Pittsburgh Dad\" would love this place n'at!!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 23.743s.\n",
      "Extracting tf features for LDA...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-ad2d84a2d83a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Use tf (raw term count) features for LDA.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Extracting tf features for LDA...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n\u001b[0m\u001b[0;32m     17\u001b[0m                                 stop_words='english')\n\u001b[0;32m     18\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "\n",
    "from time import time\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(yelp_review_sample)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "\n",
    "print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda.fit(yelp_review_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-aeaa6285dd18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcalc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec_calc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2vec_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcalc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dog+dog'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/data/insight_yelp/vectorsearch/calculator.pyc\u001b[0m in \u001b[0;36mcalc\u001b[1;34m(self, expr)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mToken\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NUM'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msplit_expr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'add'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_right_associativity\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/insight_yelp/vectorsearch/calculator.pyc\u001b[0m in \u001b[0;36mflatten_right_associativity\u001b[1;34m(self, tree)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatched\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrule_map\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflatten_right_associativity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recurse_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_right_associativity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfix_assoc_rules\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatched\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/insight_yelp/vectorsearch/calculator.pyc\u001b[0m in \u001b[0;36m_recurse_tree\u001b[1;34m(self, tree, func)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recurse_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatched\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrule_map\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflatten_right_associativity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recurse_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_right_associativity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "\n",
    "import calculator\n",
    "reload(calculator)\n",
    "\n",
    "calc = calculator.word2vec_calc(word2vec_model)\n",
    "calc.calc('dog+dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
