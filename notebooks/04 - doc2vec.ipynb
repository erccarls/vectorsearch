{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes_cool</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>votes_useful</th>\n",
       "      <th>cleaned_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>2013-11-08</td>\n",
       "      <td>Di3exaUCFNw1V4kSNW5pgA</td>\n",
       "      <td>5</td>\n",
       "      <td>All the food is great here. But the best thing...</td>\n",
       "      <td>review</td>\n",
       "      <td>uK8tzraOp4M5u3uYrqIBXg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[food, great], [best, thing, wing], [wing, si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UsFtqoBl7naz8AVUBZMjQQ</td>\n",
       "      <td>2014-03-29</td>\n",
       "      <td>0Lua2-PbqEQMjD9r89-asw</td>\n",
       "      <td>3</td>\n",
       "      <td>We checked this place out this past Monday for...</td>\n",
       "      <td>review</td>\n",
       "      <td>I_47G-R2_egp7ME5u_ltew</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[checked, place, past, monday, wing-night], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id        date               review_id  stars  \\\n",
       "10  UsFtqoBl7naz8AVUBZMjQQ  2013-11-08  Di3exaUCFNw1V4kSNW5pgA      5   \n",
       "11  UsFtqoBl7naz8AVUBZMjQQ  2014-03-29  0Lua2-PbqEQMjD9r89-asw      3   \n",
       "\n",
       "                                                 text    type  \\\n",
       "10  All the food is great here. But the best thing...  review   \n",
       "11  We checked this place out this past Monday for...  review   \n",
       "\n",
       "                   user_id  votes_cool  votes_funny  votes_useful  \\\n",
       "10  uK8tzraOp4M5u3uYrqIBXg           0            0             0   \n",
       "11  I_47G-R2_egp7ME5u_ltew           0            0             0   \n",
       "\n",
       "                                    cleaned_tokenized  \n",
       "10  [[food, great], [best, thing, wing], [wing, si...  \n",
       "11  [[checked, place, past, monday, wing-night], [...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the bar review dataset \n",
    "review = pd.read_pickle('../output/bar_reviews_cleaned_and_tokenized.pickle')\n",
    "review.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import gensim\n",
    "from itertools import chain\n",
    "import sys\n",
    "sys.path.append('../vectorsearch/')\n",
    "import nltk_helper\n",
    "import doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "\n",
    "n_epochs = 1\n",
    "n_docs = 2 # -1 for almost all of them...\n",
    "\n",
    "\n",
    "# print review.cleaned_tokenized.iloc[:n_docs]\n",
    "# print \n",
    "\n",
    "review_flatten = [list(chain.from_iterable(doc)) for doc in review.cleaned_tokenized[:n_docs]]\n",
    "\n",
    "#print review_flatten\n",
    "#review_flatten = list(chain.from_iterable(review.cleaned_tokenized.iloc[:n_docs]))\n",
    "#review_flatten = list(chain.from_iterable(review_flatten))\n",
    "# for i in review_flatten:\n",
    "#     print i \n",
    "#labels = review.review_id.iloc[:n_docs]\n",
    "#labels = ['SENT_%i'%i for i in range(n_docs)]\n",
    "\n",
    "\n",
    "# for index, words in enumerate(review_flatten[:3]):\n",
    "#     review.cleaned_tokenized.iloc[index]\n",
    "    #print index, words\n",
    "    #TaggedDocument(words, (index,)\n",
    "\n",
    "# review_flatten = [TaggedDocument(words, (index,))\n",
    "#                              for index, words in enumerate(review_flatten)]\n",
    "\n",
    "\n",
    "# it = doc2vec.LabeledLineSentence(review_flatten, labels)\n",
    "\n",
    "\n",
    "#print 'flat_review', review_flatten[0]\n",
    "\n",
    "with open('../output/reviews.txt', 'wb') as f: \n",
    "    for doc in review_flatten:\n",
    "        f.write(\" \".join(doc))\n",
    "        f.write(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = doc2vec.TaggedLineDocument('../output/reviews.txt')\n",
    "#print docs.__iter__().next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument([u'food', u'great', u'best', u'thing', u'wing', u'wing', u'simply', u'fantastic', u'wet', u'cajun', u'best', u'most', u'popular', u'also', u'like', u'seasoned', u'salt', u'wing', u'wing-night', u'monday', u'wednesday', u'night', u'075', u'whole', u'wing', u'dining', u'area', u'nice', u'very', u'family', u'friendly', u'bar', u'very', u'nice', u'well', u'place', u'truly', u'yinzers', u'dream', u'pittsburgh', u'dad', u'would', u'love', u'place', u'nat'], ['SENT_0'])\n"
     ]
    }
   ],
   "source": [
    "print docs.__iter__().next()\n",
    "\n",
    "\n",
    "# Number of training epochs\n",
    "model = gensim.models.Doc2Vec(size=100, window=10, min_count=5, \n",
    "                              workers=1, alpha=0.025, min_alpha=0.025) # use fixed learning rate\n",
    "model.build_vocab(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carlson/anaconda/envs/insight/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/carlson/anaconda/envs/insight/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/home/carlson/anaconda/envs/insight/lib/python2.7/site-packages/gensim/models/word2vec.py\", line 735, in worker_loop\n",
      "    tally, raw_tally = self._do_train_job(sentences, alpha, (work, neu1))\n",
      "  File \"/home/carlson/anaconda/envs/insight/lib/python2.7/site-packages/gensim/models/doc2vec.py\", line 672, in _do_train_job\n",
      "    doctag_vectors=doctag_vectors, doctag_locks=doctag_locks)\n",
      "  File \"gensim/models/doc2vec_inner.pyx\", line 449, in gensim.models.doc2vec_inner.train_document_dm (./gensim/models/doc2vec_inner.c:5508)\n",
      "    codes[i] = <np.uint8_t *>np.PyArray_DATA(predict_word.code)\n",
      "TypeError: Cannot convert list to numpy.ndarray\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train(docs)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SENT_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-3af17876b10b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SENT_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/carlson/anaconda/envs/insight/lib/python2.7/site-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m   1316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1318\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SENT_0'"
     ]
    }
   ],
   "source": [
    "model.vocab\n",
    "model['SENT_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
