{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               business_id        date               review_id stars  \\\n",
      "10  UsFtqoBl7naz8AVUBZMjQQ  2013-11-08  Di3exaUCFNw1V4kSNW5pgA     5   \n",
      "11  UsFtqoBl7naz8AVUBZMjQQ  2014-03-29  0Lua2-PbqEQMjD9r89-asw     3   \n",
      "\n",
      "                                                 text    type  \\\n",
      "10  All the food is great here. But the best thing...  review   \n",
      "11  We checked this place out this past Monday for...  review   \n",
      "\n",
      "                   user_id  votes_cool  votes_funny  votes_useful  \\\n",
      "10  uK8tzraOp4M5u3uYrqIBXg         0.0          0.0           0.0   \n",
      "11  I_47G-R2_egp7ME5u_ltew         0.0          0.0           0.0   \n",
      "\n",
      "                                    cleaned_tokenized  \n",
      "10  [[food, great], [best, thing, wing], [wing, si...  \n",
      "11  [[checked, place, past, monday, wing, night], ...  \n",
      "                                    business_id date  \\\n",
      "84215  8781c06a4e2407f5e027cd503f4aab675e76615b  NaN   \n",
      "84216  8781c06a4e2407f5e027cd503f4aab675e76615b  NaN   \n",
      "\n",
      "                                  review_id stars  \\\n",
      "84215  0e446098-6893-4315-9ed8-243c1926dae6   4.0   \n",
      "84216  a5eb8ce2-2f30-4f4b-885b-5d163e606629   5.0   \n",
      "\n",
      "                                                    text type  \\\n",
      "84215  Buffalo wings w/ hotter sauce - just the right...  NaN   \n",
      "84216  It's thinly sliced steak covered with cheese o...  NaN   \n",
      "\n",
      "                                    user_id  votes_cool  votes_funny  \\\n",
      "84215  d1d2fa20-3413-41ee-adc2-b58bc9b160e8         NaN          NaN   \n",
      "84216  4585e5c9-f4b7-4bdb-94d4-39dc8e124db6         NaN          NaN   \n",
      "\n",
      "       votes_useful                                  cleaned_tokenized  \n",
      "84215           NaN  [[buffalo, wing, w, hotter, sauce, -, right, a...  \n",
      "84216           NaN  [[thinly, sliced, steak, covered, cheese, warm...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the bar review dataset \n",
    "review = pd.read_pickle('../output/bar_reviews_cleaned_and_tokenized_SF.pickle')\n",
    "print review.head(2)\n",
    "print review.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training users\n",
    "user_set_training = pickle.load(open('../output/training_users.pickle', 'rb'))\n",
    "# Make the active review set training only \n",
    "review = review[review.user_id.isin(user_set_training)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fraction Processed 0.999781992588\n",
      "4587\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "# n_reviews = 100 # all of them... \n",
    "# Flatten the reviews, so each review is just a single list of words.\n",
    "reviews_merged_bus = OrderedDict()\n",
    "business_set = list(set(review.business_id.values[:]))\n",
    "for i_bus, bus_id in enumerate(business_set):\n",
    "    if ((i_bus%5)==0):\n",
    "        print '\\r Fraction Processed',float(i_bus+1)/len(business_set),\n",
    "    # This horrible line first collapses each review of a corresponding business into a list\n",
    "    # of lists, and then collapses the list of sentences to a long list of words\n",
    "    reviews_merged_bus[bus_id] = list(chain.from_iterable(chain.from_iterable( \n",
    "                                     review.cleaned_tokenized[review.business_id==bus_id] )) )\n",
    "docs_bus = reviews_merged_bus.values()\n",
    "print \n",
    "print len(docs_bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First Doc: \n",
      "-----------------\n",
      "TaggedDocument(['apparently', 'place', 'get', 'pitcher', 'beer', 'very', 'late', 'sunday', 'evening', 'isnt', 'filled', 'drunk', 'karaoke', 'bad', 'house', 'music', 'dont', 'get', 'wrong', 'love', 'karaoke', 'dancing', 'like', 'go', u'place', 'actually', 'hear', 'person', 'next', 'place', 'run', 'people', 'went', 'high', 'school', 'might', 'want', 'make', 'sure', 'wearing', 'matching', u'sock', 'could', 'embarrassing', 'bartender', 'really', 'feel', 'badly', 'forgetting', 'name', 'super', 'nice', 'let', u'u', 'stay', 'finish', u'drink', 'shoot', 'shit', 'much', 'area', 'changed', 'good', '20', u'min', 'past', 'close', 'busy', 'enough', 'dont', 'feel', 'awkward', 'drinking', 'yet', 'not', 'busy', 'cant', 'get', 'seat', 'good', 'service', u'drink', 'affordable', 'really', 'cant', 'complain', u'the-only-place', u'a-pitcher', u'the-person', u'a-place', u'high-school', u'her-name', u'our-drinks', u'the-shit', u'this-area', u'a-good-20-mins', u'a-seat', u'good-service', u'the-drinks', 'bad', 'flopped', 'another', 'one', u'bite', 'dust', 'ab', u'another-one', u'the-dust', 'one', 'word', 'assault', 'two', u'word', u'charge', 'pending', 'not', 'go', 'bar', 'bouncer', 'assaulted', 'best', 'would', 'hate', 'think', 'gay', 'male', 'westside', 'town', 'no', 'other', u'reason', 'come', 'mind', u'this-bar', u'the-bouncer', u'my-best-friend', u'a-gay-male', u'the-westside'], [u'TQasUKgKxJGMINAXuNE63A'])\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from itertools import chain\n",
    "import sys\n",
    "sys.path.append('../vectorsearch/')\n",
    "import nltk_helper\n",
    "import doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import pandas as pd\n",
    "n_epochs = 10\n",
    "n_docs = 10 # -1 for almost all of them...\n",
    "\n",
    "# Generate the tagged document list. \n",
    "\n",
    "docs = [TaggedDocument(words, [business_set[index],])\n",
    "                             for index, words in enumerate(docs_bus[:])]\n",
    "\n",
    "print '\\nFirst Doc: \\n-----------------\\n', docs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "\n",
    "model = doc2vec.Doc2Vec(min_count=5, window=6, size=100, sample=1e-4, negative=5, workers=12)\n",
    "# Build the vocab from list of sentences.\n",
    "model.build_vocab(docs) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 10, alpha 0.0160\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "for epoch in range(10):\n",
    "    print '\\rTraining Epoch %i, alpha %1.4f'%(epoch+1, model.alpha),\n",
    "    #model.train(np.random.permutation(docs))\n",
    "    shuffle(docs)\n",
    "    model.train(docs)\n",
    "    model.alpha -= 0.001 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no decay\n",
    "\n",
    "#model.init_sims(replace=True)    \n",
    "# # Normalize the word vectors.\n",
    "# vec_norms = np.sqrt(np.sum(model.syn0**2, axis=1))\n",
    "# model.syn0 = (model.syn0/vec_norms[:, numpy.newaxis])\n",
    "# # Normalize the doc vectors.\n",
    "# vec_norms = np.sqrt(np.sum(model.docvecs.doctag_syn0**2, axis=1))\n",
    "# model.docvecs.doctag_syn0 = (model.docvecs.doctag_syn0/vec_norms[:, numpy.newaxis])\n",
    "\n",
    "model.save('../output/doc2vec_bars_100.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'yyUJKvG-C4VipITrAS0nIQ', 0.6710823774337769), (u'g3fipTPN2LBe_U42niTDcw', 0.6688743829727173), (u'ANaGwB8tVAc1qM1QAJecsQ', 0.6611914038658142), (u'LVjRN5pMJ8hhDmX0lbclpQ', 0.6471917629241943), (u'YP-sxa8i95v_scvXN2o4_w', 0.6342615485191345), (u'XkyZAQAaGO9i3on-b3fswg', 0.6326159834861755), (u'qdTtkZVgcdu3SEA6tzBPdw', 0.6320397853851318), (u'L7eGNKkuy_XdQ_35Y1Kacg', 0.629540741443634), (u'cd46siFt_-08j9-kSbVEgA', 0.6246991157531738), (u'3mp5jXdxC2yqSK6sgRQfEg', 0.6225901246070862)] \n",
      "\n",
      "[('draft', 0.7733069062232971), (u'wine', 0.7592223882675171), ('tap', 0.7554447054862976), ('micro-brews', 0.7395221590995789), ('brew', 0.7344582080841064), (u'cocktail', 0.7317838072776794), ('draught', 0.7313833236694336), ('selection', 0.723392128944397), ('bottled', 0.71184903383255), ('whisky', 0.6925665140151978)] \n",
      "\n",
      "[(u'W3SROyBvrFKT5C2ySdx1qw', 0.44849711656570435), (u'6w6gMZ3iBLGcUM4RBIuifQ', 0.43213915824890137), (u'KCP4tSmVRD6Gk3xbPEAf3w', 0.3971535861492157), (u'3WsATGkAIXV-56eWjdzecw', 0.3879733681678772), (u'3jzEz2q9HZYF2XU1Gm41nA', 0.3710145354270935), (u'JS0gYaJR5HZDhZG0TJRRGg', 0.3570679724216461), (u'QSmI5Y9bhCLIw9YYKOiQkg', 0.34995037317276), (u'Bxn0LTYR9BxEeXReFbXDJA', 0.34519267082214355), (u'Ejw0lND0g8WBQj4pCllUnQ', 0.3383505046367645), (u'EaAo1G89msEiSQLi1jX_Hw', 0.33163875341415405)] \n",
      "\n",
      "[ u'My brother and I make the trek from N Scottsdale to The Drummer almost every weekend.   Jesse makes the HOTTEST suicide grilled wings on the planet - we love \\'em!  Service is great and the \"regulars\" are pretty friendly too.  Drink prices are good and there are plenty of TV\\'s.  One of the better \"dive bars\" in the area.']\n",
      "[('rory', 0.5823439359664917), ('carin', 0.5686616897583008), ('biotch', 0.5440913438796997), ('seit', 0.5418999195098877), ('uwe', 0.5400148034095764), ('reaffirms', 0.5130881071090698), ('accoustic', 0.512511134147644), ('gaurd', 0.5113624930381775), ('wrist', 0.5096732974052429), ('self-guided', 0.4946335256099701)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Can find similar documents..\n",
    "print model.docvecs.most_similar(positive=['KUinHkKyGhznElgIzx0yIw']), '\\n'\n",
    "\n",
    "# Can find similar words...Re: Dream Companies and contact from recruiters\n",
    "print model.most_similar(positive=['beer']), '\\n'\n",
    "\n",
    "# Can find documents that are most similar to keywords.... \n",
    "print model.docvecs.most_similar(positive=[model['beer'], model['music']]), '\\n'\n",
    "\n",
    "# Can find words that are most common in documents\n",
    "print review.text[review.review_id=='KUinHkKyGhznElgIzx0yIw'].values\n",
    "print model.most_similar(positive=[model.docvecs['KUinHkKyGhznElgIzx0yIw']]), '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
